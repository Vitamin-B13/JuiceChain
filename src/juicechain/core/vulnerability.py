from __future__ import annotations
from .dom_xss import verify_dom_xss_on_search
import re
import secrets
import time
from dataclasses import dataclass
from typing import Any, Mapping
from urllib.parse import parse_qsl, urlparse

from .http_client import HttpClient, HttpResponse
from .target import join_url, normalize_target_base


@dataclass(frozen=True)
class InputPoint:
    method: str           # GET/POST/...
    path: str             # /rest/user/login
    location: str         # query/json/body
    param: str            # q / email / password
    content_type: str | None = None
    sample: str | None = None
    source: str | None = None

    def key(self) -> tuple[str, str, str, str]:
        return (self.method, self.path, self.location, self.param)


@dataclass
class Finding:
    type: str
    severity: str
    evidence: str
    request: dict[str, Any]
    response: dict[str, Any] | None = None
    timestamp: int | None = None

    def to_dict(self) -> dict[str, Any]:
        return {
            "type": self.type,
            "severity": self.severity,
            "evidence": self.evidence,
            "request": self.request,
            "response": self.response,
            "timestamp": self.timestamp,
        }


# Common SQL error hints (error-based heuristic)
_SQL_ERR_PATTERNS = [
    r"sqlite_error",
    r"sqlite3::SQLException".lower(),
    r"sequelize(database)?error",
    r"sql syntax",
    r"syntax error",
    r"unterminated",
    r"unrecognized token",
    r"near \"",
    r"odbc",
    r"mysql",
    r"postgres",
    r"psql",
]
_SQL_ERR_RE = re.compile("|".join(_SQL_ERR_PATTERNS), re.IGNORECASE)

# XSS: this stage only flags when HTML response reflects script tag payload literally
_HTML_HINT_RE = re.compile(r"(?is)<\s*(html|head|body)\b")


def _safe_get_base_from_scan(doc: Mapping[str, Any]) -> str | None:
    alive = doc.get("alive") or {}
    t1 = alive.get("target")
    if isinstance(t1, str) and t1.strip():
        try:
            return normalize_target_base(t1)
        except Exception:
            pass

    t0 = doc.get("target")
    if isinstance(t0, str) and t0.strip():
        try:
            return normalize_target_base(t0)
        except Exception:
            return None

    return None


def derive_input_points_from_scan(doc: Mapping[str, Any]) -> list[InputPoint]:
    """
    Derive injection points from week4 scan.json.

    Current sources:
    - enum.crawler.spa.api_candidates_from_assets: parse query string parameters -> query points
    - minimal Juice Shop heuristic:
        * /rest/user/login -> JSON body fields: email/password (POST)
    """
    enum = doc.get("enum") or {}
    crawler = (enum.get("crawler") or {}) if isinstance(enum, Mapping) else {}
    spa = (crawler.get("spa") or {}) if isinstance(crawler, Mapping) else {}
    api_candidates = spa.get("api_candidates_from_assets") or []

    points: list[InputPoint] = []

    if isinstance(api_candidates, list):
        for raw in api_candidates:
            if not isinstance(raw, str):
                continue
            s = raw.strip()
            if not s.startswith("/"):
                continue

            p = urlparse(s)
            path = p.path or ""
            if not path:
                continue

            # query params => GET query input points
            for k, v in parse_qsl(p.query, keep_blank_values=True):
                k = (k or "").strip()
                if not k:
                    continue
                points.append(
                    InputPoint(
                        method="GET",
                        path=path,
                        location="query",
                        param=k,
                        sample=v if v != "" else None,
                        source="spa_api_candidate",
                    )
                )

            # heuristic: login endpoint uses JSON body
            if path.rstrip("/") == "/rest/user/login":
                for field in ("email", "password"):
                    points.append(
                        InputPoint(
                            method="POST",
                            path=path,
                            location="json",
                            param=field,
                            content_type="application/json",
                            source="heuristic_login_body",
                        )
                    )
    
        # builtin: Juice Shop product search (high-value input)
    points.append(
        InputPoint(
            method="GET",
            path="/rest/products/search",
            location="query",
            param="q",
            sample=None,
            source="builtin_products_search",
        )
    )

    # de-dup
    uniq: dict[tuple[str, str, str, str], InputPoint] = {}
    for pt in points:
        uniq[pt.key()] = pt
    return list(uniq.values())


def summarize_input_points(points: list[InputPoint]) -> dict[str, Any]:
    by_location: dict[str, int] = {}
    by_method: dict[str, int] = {}
    by_path: dict[str, int] = {}

    for p in points:
        by_location[p.location] = by_location.get(p.location, 0) + 1
        by_method[p.method] = by_method.get(p.method, 0) + 1
        by_path[p.path] = by_path.get(p.path, 0) + 1

    top_paths = sorted(by_path.items(), key=lambda x: (-x[1], x[0]))[:10]
    return {
        "total": len(points),
        "by_location": dict(sorted(by_location.items())),
        "by_method": dict(sorted(by_method.items())),
        "top_paths": [{"path": p, "count": c} for p, c in top_paths],
    }


def vuln_dry_run_report(scan_doc: Mapping[str, Any], *, version: str) -> dict[str, Any]:
    t0 = time.time()
    base = _safe_get_base_from_scan(scan_doc)

    points = derive_input_points_from_scan(scan_doc)
    stats = summarize_input_points(points)

    return {
        "meta": {
            "tool": "juicechain",
            "version": version,
            "timestamp": int(time.time()),
            "duration_ms": int(round((time.time() - t0) * 1000)),
            "mode": "dry-run",
        },
        "target": {"raw": scan_doc.get("target"), "base": base},
        "input_points": stats,
        "findings": [],
        "errors": [],
    }


def _is_html_response(res: HttpResponse) -> bool:
    ct = (res.content_type() or "").lower()
    if "text/html" in ct:
        return True
    t = res.text()
    return bool(_HTML_HINT_RE.search(t))


def _snippet_around(text: str, needle: str, *, radius: int = 80) -> str:
    if not text or not needle:
        return ""
    i = text.find(needle)
    if i < 0:
        return ""
    start = max(0, i - radius)
    end = min(len(text), i + len(needle) + radius)
    return text[start:end].replace("\n", " ").replace("\r", " ").strip()

def _try_json(text: str) -> Any | None:
    try:
        import json
        return json.loads(text)
    except Exception:
        return None


def _count_items(obj: Any) -> int | None:
    # Juice Shop search often returns {"data":[...], ...}
    if isinstance(obj, list):
        return len(obj)
    if isinstance(obj, dict):
        if isinstance(obj.get("data"), list):
            return len(obj["data"])
        if isinstance(obj.get("products"), list):
            return len(obj["products"])
    return None


def check_reflected_xss(
    *,
    base: str,
    pt: InputPoint,
    client: HttpClient,
    timeout: float,
    max_bytes: int,
) -> Finding | None:
    """
    Stage-1 (safe) reflected XSS check:
    - Only flag when HTML response includes script-tag payload literally.
    - This avoids claiming DOM-XSS on SPA pages (needs headless browser; later).
    """
    if pt.location != "query" or pt.method != "GET":
        return None

    token = secrets.token_hex(4)
    payload = f'<script>JCXSS_{token}</script>'
    url = join_url(base, pt.path)

    res = client.request("GET", url, timeout=timeout, max_bytes=max_bytes, params={pt.param: payload})
    if not res.ok:
        return None

    if not _is_html_response(res):
        return None

    text = res.text()
    if payload not in text:
        return None

    evidence = f"payload reflected in HTML response: ...{_snippet_around(text, payload)}..."
    return Finding(
        type="XSS_REFLECTED",
        severity="high",
        evidence=evidence,
        request={"method": "GET", "url": url, "location": pt.location, "param": pt.param, "payload": payload},
        response={"status_code": res.status_code, "content_type": res.content_type(), "time_ms": res.response_time_ms},
        timestamp=int(time.time()),
    )


def check_sqli_error(
    *,
    base: str,
    pt: InputPoint,
    client: HttpClient,
    timeout: float,
    max_bytes: int,
    json_field_group: dict[tuple[str, str], list[InputPoint]],
) -> Finding | None:
    """
    Minimal error-based SQLi check:
    - query: send payloads as single parameter
    - json: for /rest/user/login, build json body including both email/password; inject one field at a time
    """
    payloads = ["'", "' OR '1'='1'--", "\"", "\" OR \"1\"=\"1\"--"]

    # query injection
    if pt.location == "query" and pt.method == "GET":
        url = join_url(base, pt.path)
        for payload in payloads[:2]:
            res = client.request("GET", url, timeout=timeout, max_bytes=max_bytes, params={pt.param: payload})
            if not res.ok:
                continue
            text = res.text()
            if _SQL_ERR_RE.search(text):
                evidence = f"possible SQL error keyword in response: ...{_snippet_around(text.lower(), 'error')}..."
                return Finding(
                    type="SQLI_ERROR",
                    severity="high",
                    evidence=evidence,
                    request={"method": "GET", "url": url, "location": pt.location, "param": pt.param, "payload": payload},
                    response={"status_code": res.status_code, "content_type": res.content_type(), "time_ms": res.response_time_ms},
                    timestamp=int(time.time()),
                )
        return None

    # json injection (grouped by endpoint)
    if pt.location == "json" and pt.method == "POST":
        url = join_url(base, pt.path)
        key = (pt.method, pt.path)
        group = json_field_group.get(key) or [pt]

        # Build base body: other fields as benign filler
        base_body: dict[str, Any] = {}
        for g in group:
            base_body[g.param] = g.sample if g.sample is not None else "test"

        for payload in payloads[:2]:
            body = dict(base_body)
            body[pt.param] = payload

            res = client.request(
                "POST",
                url,
                timeout=timeout,
                max_bytes=max_bytes,
                headers={"Content-Type": "application/json"},
                json_data=body,
            )
            if not res.ok:
                continue
            text = res.text()
            if _SQL_ERR_RE.search(text):
                evidence = f"possible SQL error keyword in response: ...{_snippet_around(text, 'error')}..."
                return Finding(
                    type="SQLI_ERROR",
                    severity="high",
                    evidence=evidence,
                    request={"method": "POST", "url": url, "location": pt.location, "param": pt.param, "payload": payload},
                    response={"status_code": res.status_code, "content_type": res.content_type(), "time_ms": res.response_time_ms},
                    timestamp=int(time.time()),
                )
        return None

    return None

def check_sqli_boolean(
    *,
    base: str,
    pt: InputPoint,
    client: HttpClient,
    timeout: float,
    max_bytes: int,
) -> Finding | None:
    """
    Boolean-based SQLi oracle:
    baseline(q=random) vs injection(q=' OR 1=1-- )
    Decide by item count (preferred) or response length delta.
    """
    if not (pt.method == "GET" and pt.location == "query"):
        return None

    if not (pt.path.rstrip("/") == "/rest/products/search" and pt.param == "q"):
        return None

    url = join_url(base, pt.path)

    baseline_token = f"jc_{secrets.token_hex(4)}"
    inj = "' OR 1=1-- "

    r0 = client.request("GET", url, timeout=timeout, max_bytes=max_bytes, params={pt.param: baseline_token})
    r1 = client.request("GET", url, timeout=timeout, max_bytes=max_bytes, params={pt.param: inj})

    if not (r0.ok and r1.ok):
        return None
    
    if (r0.status_code is None) or (r1.status_code is None):
        return None
    if r0.status_code >= 400 or r1.status_code >= 400:
        return None

    ct1 = (r1.content_type() or "").lower()
    if "application/json" not in ct1:
        return None

    t0 = r0.text()
    t1 = r1.text()

    j0 = _try_json(t0)
    j1 = _try_json(t1)
    c0 = _count_items(j0) if j0 is not None else None
    c1 = _count_items(j1) if j1 is not None else None

    # Prefer count oracle
    if c0 is not None and c1 is not None:
        if c1 >= max(5, (c0 + 5)):
            evidence = f"item count changed (baseline={c0}, injected={c1})"
            return Finding(
                type="SQLI_BOOLEAN",
                severity="high",
                evidence=evidence,
                request={"method": "GET", "url": url, "location": pt.location, "param": pt.param, "payload": inj},
                response={"status_code": r1.status_code, "content_type": r1.content_type(), "time_ms": r1.response_time_ms},
                timestamp=int(time.time()),
            )

    # Fallback: length oracle
    if len(t1) >= len(t0) + 800 and len(t1) >= len(t0) * 2:
        evidence = f"response length changed (baseline={len(t0)}, injected={len(t1)})"
        return Finding(
            type="SQLI_BOOLEAN",
            severity="medium",
            evidence=evidence,
            request={"method": "GET", "url": url, "location": pt.location, "param": pt.param, "payload": inj},
            response={"status_code": r1.status_code, "content_type": r1.content_type(), "time_ms": r1.response_time_ms},
            timestamp=int(time.time()),
        )

    return None

def scan_vulnerabilities(
    scan_doc: Mapping[str, Any],
    *,
    version: str,
    timeout: float = 3.0,
    verify_tls: bool = True,
    allow_redirects: bool = False,
    retries: int = 0,
    min_interval_ms: int = 0,
    max_bytes: int = 200_000,
    enable_dom_xss: bool = False,
    dom_xss_headless: bool = True,
) -> dict[str, Any]:
    """
    Run basic vuln checks against derived input points.
    Only use on authorized targets / local labs (e.g., Juice Shop).
    """
    t0 = time.time()
    errors: list[str] = []
    has_sqli_error: set[tuple[str, str, str, str]] = set()

    base = _safe_get_base_from_scan(scan_doc)
    if not base:
        return {
            "meta": {"tool": "juicechain", "version": version, "timestamp": int(time.time()), "duration_ms": 0, "mode": "scan"},
            "target": {"raw": scan_doc.get("target"), "base": None},
            "input_points": {"total": 0, "by_location": {}, "by_method": {}, "top_paths": []},
            "findings": [],
            "errors": ["could not determine target base url from scan.json"],
        }

    points = derive_input_points_from_scan(scan_doc)
    stats = summarize_input_points(points)

    # Group json fields by endpoint (method+path)
    json_group: dict[tuple[str, str], list[InputPoint]] = {}
    for p in points:
        if p.location == "json":
            json_group.setdefault((p.method, p.path), []).append(p)

    findings: list[Finding] = []

    client = HttpClient(
        timeout=timeout,
        verify_tls=verify_tls,
        allow_redirects=allow_redirects,
        max_bytes=max_bytes,
        retries=retries,
        min_interval_ms=min_interval_ms,
    )

    try:
        for pt in points:
            try:
                f1 = check_reflected_xss(base=base, pt=pt, client=client, timeout=timeout, max_bytes=max_bytes)
                if f1:
                    findings.append(f1)

                f2 = check_sqli_error(
                    base=base,
                    pt=pt,
                    client=client,
                    timeout=timeout,
                    max_bytes=max_bytes,
                    json_field_group=json_group,
                )
                
                if f2:
                    findings.append(f2)
                    if f2.type == "SQLI_ERROR":
                        has_sqli_error.add((pt.method, pt.path, pt.location, pt.param))

                if (pt.method, pt.path, pt.location, pt.param) not in has_sqli_error:
                    f3 = check_sqli_boolean(base=base, pt=pt, client=client, timeout=timeout, max_bytes=max_bytes)
                    if f3:
                        findings.append(f3)

            except Exception as e:
                errors.append(f"{type(e).__name__}: {e} @ {pt.method} {pt.path} {pt.location} {pt.param}")

    finally:
        client.close()

    if enable_dom_xss:
        r = verify_dom_xss_on_search(base=base, headless=dom_xss_headless)
        if r.error:
            errors.append(f"DOM_XSS: {r.error}")
        elif r.ok:
            findings.append(
                Finding(
                    type="XSS_DOM",
                    severity="high",
                    evidence=f"browser dialog captured: {r.dialog_message!r}",
                    request={"method": "BROWSER", "url": r.url, "location": "dom", "param": "q", "payload": r.payload},
                    response={"status_code": None, "content_type": "browser/dialog", "time_ms": r.duration_ms},
                    timestamp=int(time.time()),
                )
            )

    out = {
        "meta": {
            "tool": "juicechain",
            "version": version,
            "timestamp": int(time.time()),
            "duration_ms": int(round((time.time() - t0) * 1000)),
            "mode": "scan",
        },
        "target": {"raw": scan_doc.get("target"), "base": base},
        "input_points": stats,
        "findings": [f.to_dict() for f in findings],
        "errors": errors,
    }
    return out

