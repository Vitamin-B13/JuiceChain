from __future__ import annotations

import time
from dataclasses import dataclass
from typing import Any, Mapping
from urllib.parse import parse_qsl, urlparse

from .target import normalize_target_base


@dataclass(frozen=True)
class InputPoint:
    method: str           # GET/POST/...
    path: str             # /rest/user/login
    location: str         # query/body/json
    param: str            # q / email / password
    content_type: str | None = None
    sample: str | None = None
    source: str | None = None

    def key(self) -> tuple[str, str, str, str]:
        return (self.method, self.path, self.location, self.param)


def _safe_get_base_from_scan(doc: Mapping[str, Any]) -> str | None:
    """
    Prefer alive.target (usually already normalized to http(s)://host[:port]).
    Fallback to top-level target.
    """
    alive = doc.get("alive") or {}
    t1 = alive.get("target")
    if isinstance(t1, str) and t1.strip():
        try:
            return normalize_target_base(t1)
        except Exception:
            pass

    t0 = doc.get("target")
    if isinstance(t0, str) and t0.strip():
        try:
            return normalize_target_base(t0)
        except Exception:
            return None

    return None


def derive_input_points_from_scan(doc: Mapping[str, Any]) -> list[InputPoint]:
    """
    Derive injection points from week4 scan.json.

    Current heuristic sources:
    - enum.crawler.spa.api_candidates_from_assets: parse query string parameters
    - minimal Juice Shop heuristics:
        * /rest/user/login -> JSON body fields: email/password (POST)
    """
    enum = doc.get("enum") or {}
    crawler = (enum.get("crawler") or {}) if isinstance(enum, Mapping) else {}
    spa = (crawler.get("spa") or {}) if isinstance(crawler, Mapping) else {}
    api_candidates = spa.get("api_candidates_from_assets") or []

    points: list[InputPoint] = []

    if isinstance(api_candidates, list):
        for raw in api_candidates:
            if not isinstance(raw, str):
                continue
            s = raw.strip()
            if not s.startswith("/"):
                continue

            p = urlparse(s)
            path = p.path or ""
            if not path:
                continue

            # query params => GET query input points
            for k, v in parse_qsl(p.query, keep_blank_values=True):
                k = (k or "").strip()
                if not k:
                    continue
                points.append(
                    InputPoint(
                        method="GET",
                        path=path,
                        location="query",
                        param=k,
                        content_type=None,
                        sample=v if v != "" else None,
                        source="spa_api_candidate",
                    )
                )

            # heuristic: login endpoint uses JSON body
            if path.rstrip("/") == "/rest/user/login":
                for field in ("email", "password"):
                    points.append(
                        InputPoint(
                            method="POST",
                            path=path,
                            location="json",
                            param=field,
                            content_type="application/json",
                            sample=None,
                            source="heuristic_login_body",
                        )
                    )

    # de-dup
    uniq: dict[tuple[str, str, str, str], InputPoint] = {}
    for pt in points:
        uniq[pt.key()] = pt
    return list(uniq.values())


def summarize_input_points(points: list[InputPoint]) -> dict[str, Any]:
    by_location: dict[str, int] = {}
    by_method: dict[str, int] = {}
    by_path: dict[str, int] = {}

    for p in points:
        by_location[p.location] = by_location.get(p.location, 0) + 1
        by_method[p.method] = by_method.get(p.method, 0) + 1
        by_path[p.path] = by_path.get(p.path, 0) + 1

    top_paths = sorted(by_path.items(), key=lambda x: (-x[1], x[0]))[:10]
    return {
        "total": len(points),
        "by_location": dict(sorted(by_location.items())),
        "by_method": dict(sorted(by_method.items())),
        "top_paths": [{"path": p, "count": c} for p, c in top_paths],
    }


def vuln_dry_run_report(scan_doc: Mapping[str, Any], *, version: str) -> dict[str, Any]:
    t0 = time.time()
    base = _safe_get_base_from_scan(scan_doc)

    points = derive_input_points_from_scan(scan_doc)
    stats = summarize_input_points(points)

    return {
        "meta": {
            "tool": "juicechain",
            "version": version,
            "timestamp": int(time.time()),
            "duration_ms": int(round((time.time() - t0) * 1000)),
            "mode": "dry-run",
        },
        "target": {
            "raw": scan_doc.get("target"),
            "base": base,
        },
        "input_points": stats,
        "findings": [],
    }